#!/bin/python

"""Generate text automatically from text in Aozora Bunko using Markov chain"""

import codecs
# import random
import re
import sys
import argparse

from urllib.request import urlopen
from urllib.error import HTTPError, URLError
from bs4 import BeautifulSoup
from janome.tokenizer import Tokenizer
from markovify import NewlineText


class GetAutoGeneratedText(object):
    """Generate text using Markov chain"""

    def __init__(self, location, sentences):
        """Constructor: prepare text"""

        self.sentences = sentences
        self.remove_pattern = "[　★―\r\n]"
        self.punct_pattern = "[。？！]"
        self.gram = 3

        content = self.get_beautifulsoup_from_html(location)
        self.text = self.get_text(content)

        self.tokenizer = Tokenizer()
        self.tokenized_text = self.tokenize()

    def generate_text(self):
        """Generate text using tokenized text and Markov chain"""

        text_model = NewlineText(self.tokenized_text)
        sentences = []
        for _ in range(self.sentences):
            generated_sentence = text_model.make_sentence()
            sentence = generated_sentence.replace(' ', '') + "。"
            sentences.append(sentence)
        text = ''.join(sentences)
        return text

    def get_text(self, content):
        """Return text removed garbage characters"""
        pattern = re.compile(self.remove_pattern)
        text = pattern.sub('', content)
        return text

    @staticmethod
    def get_beautifulsoup_from_html(location):
        """Return BeautifulSoup object from HTML which located to
        given location"""

        if "http" in location[:5]:
            try:
                file_object = urlopen(location)
                html = file_object.read()
            except (HTTPError, URLError) as caught_error:
                sys.stderr.write(caught_error)
                sys.exit(1)
        else:
            try:
                with codecs.open(location, 'r', "Shift-JIS") as file_object:
                    html = file_object.read()
            except ValueError as caught_error:
                sys.stderr.write(caught_error)
                sys.exit(1)

        soup = BeautifulSoup(html, "html.parser")
        content = soup.find("div", {"class": "main_text"}).get_text()
        return content

    def tokenize(self):
        """Tokenize sentences in self.listed_sentences"""

        pattern = re.compile(self.punct_pattern)
        tokenized_list = []
        for text in pattern.split(self.text):
            tokens = self.tokenizer.tokenize(text)
            tokenized_list.append(
                ' '.join([token.surface for token in tokens])
                )
        tokenized_text = '\n'.join(tokenized_list)
        return tokenized_text


if __name__ == "__main__":
    PARSER = argparse.ArgumentParser(
        description="Get auto-generated text from given Aozora Bunko HTML")
    PARSER.add_argument(
        "location",
        metavar="<location>",
        type=str,
        help="Location for Aozora Bunko HTML")
    PARSER.add_argument(
        "sentences_number",
        metavar="<sentences_number>",
        type=int,
        help="Number of sentences you want to get from given text")

    ARGS = PARSER.parse_args()
    LOCATION = ARGS.location
    SENTENCES_NUMBER = ARGS.sentences_number

    WORK = GetAutoGeneratedText(LOCATION, SENTENCES_NUMBER)
    GOT_TEXT = WORK.generate_text()
    print(GOT_TEXT)
